{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Hyperparameter Tuning.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0L2xYCBDYPx"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwL-YXF5DYP6"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "This notebook was made in order to give a brief introduction to hyperparameter tuning. A comparison between the most basic algorithms is shown. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCtBDu_qDnWK",
        "outputId": "5a03b50c-c642-471e-dec2-80a481a18632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install keras-tuner==1.0.2 aisaratuners==1.4.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner==1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.6MB/s \n",
            "\u001b[?25hCollecting aisaratuners==1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/b9/ae5c75ee5632a729ff0206ce9d3de17099ec55f06783a17b4008a1818bb3/aisaratuners-1.4.3-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2) (20.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2) (1.18.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow>=1.15 in /usr/local/lib/python3.6/dist-packages (from aisaratuners==1.4.3) (2.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from aisaratuners==1.4.3) (1.1.5)\n",
            "Collecting plotly>=4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/09/315462259ab7b60a3d4b7159233ed700733c87d889755bdc00a9fb46d692/plotly-4.14.1-py2.py3-none-any.whl (13.2MB)\n",
            "\u001b[K     |████████████████████████████████| 13.2MB 249kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner==1.0.2) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner==1.0.2) (0.17.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (3.12.4)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (1.34.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (0.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.15->aisaratuners==1.4.3) (0.36.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->aisaratuners==1.4.3) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->aisaratuners==1.4.3) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.6.0->aisaratuners==1.4.3) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=1.15->aisaratuners==1.4.3) (50.3.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (3.3.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.15->aisaratuners==1.4.3) (3.4.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=9333ab183934522824acd0da79e54ae047a6dbe363607ea0043cf29bd7c3b3b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15357 sha256=288ff03f86e0450e21b85b71c42bfae4d869d4e099bb9c8124fe2ce8f59656b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner, plotly, aisaratuners\n",
            "  Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed aisaratuners-1.4.3 colorama-0.4.4 keras-tuner-1.0.2 plotly-4.14.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miI_tTTvDYP7"
      },
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import kerastuner as kt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfeX8YE5DYP8"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GODIRNxgDYP9",
        "outputId": "a57c9d60-f5ed-433f-a0c6-2984caa46283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import dataset\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# Preprocessing\n",
        "# x_train = np.expand_dims(x_train, axis=3).astype('float32')/255.0\n",
        "# x_test = np.expand_dims(x_test, axis=3)/255.0\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkKBqGCXDYP9",
        "outputId": "e40e065b-b5f1-454a-c0b1-4bf1744e934d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "random_sample_idx =  np.random.randint(0, len(x_train)-1)\n",
        "# plt.imshow(x_train[random_sample_idx], cmap='gray')\n",
        "plt.imshow(x_train[random_sample_idx])\n",
        "plt.show()\n",
        "print(f'label: {y_train[random_sample_idx]}')\n",
        "print(f'input shape: {len(x_train[0])} by {len(x_train[0][0])}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label: [8]\n",
            "input shape: 32 by 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xitgzwzeDYP-"
      },
      "source": [
        "## Model Definition\n",
        "A simple classification model based on Convolutional Neuronal Networks will be used. It consists of three Convolutional layers with ReLU activations, MaxPooling and dropout regularization for encoding the image, and a two-layered Fully-Connected Network for classifying."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Ou9_gCDYP-"
      },
      "source": [
        "# Setting Environment\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D,Dense, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "if physical_devices:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "INPUT_SHAPE = x_train[0].shape\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS = 25\n",
        "SEED = 37\n",
        "\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGqeeBuuDYP_"
      },
      "source": [
        "## Baseline Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHZtu096DYP_"
      },
      "source": [
        "# Model Definition\n",
        "tf.random.set_seed(SEED)\n",
        "model = keras.Sequential()\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=3,\n",
        "        activation='relu',\n",
        "        input_shape=INPUT_SHAPE\n",
        "    )\n",
        ")\n",
        "model.add(Conv2D(16, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Conv2D(32, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-3),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMf0mhJGDYQA"
      },
      "source": [
        "### Training Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U7_YvTADYQC",
        "outputId": "1eec9619-730d-49ad-ae7e-59cb0e4cb698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "start_t = time.time()\n",
        "model.fit(x_train, y_train, epochs=EPOCHS, validation_split=0.1)\n",
        "end_t = time.time()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.6596 - accuracy: 0.3851 - val_loss: 1.4066 - val_accuracy: 0.5016\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.3508 - accuracy: 0.5131 - val_loss: 1.1472 - val_accuracy: 0.6028\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.2256 - accuracy: 0.5611 - val_loss: 1.0963 - val_accuracy: 0.6146\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.1297 - accuracy: 0.5981 - val_loss: 0.9951 - val_accuracy: 0.6496\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0647 - accuracy: 0.6214 - val_loss: 0.9191 - val_accuracy: 0.6740\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0103 - accuracy: 0.6438 - val_loss: 0.9185 - val_accuracy: 0.6768\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9805 - accuracy: 0.6526 - val_loss: 0.8734 - val_accuracy: 0.6968\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9488 - accuracy: 0.6640 - val_loss: 0.9148 - val_accuracy: 0.6834\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9268 - accuracy: 0.6709 - val_loss: 0.8373 - val_accuracy: 0.7106\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9020 - accuracy: 0.6799 - val_loss: 0.8124 - val_accuracy: 0.7120\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8896 - accuracy: 0.6850 - val_loss: 0.8167 - val_accuracy: 0.7192\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8689 - accuracy: 0.6924 - val_loss: 0.7912 - val_accuracy: 0.7252\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8521 - accuracy: 0.6971 - val_loss: 0.7666 - val_accuracy: 0.7320\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8411 - accuracy: 0.6996 - val_loss: 0.8071 - val_accuracy: 0.7210\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8304 - accuracy: 0.7055 - val_loss: 0.7639 - val_accuracy: 0.7328\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8161 - accuracy: 0.7066 - val_loss: 0.7874 - val_accuracy: 0.7236\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8088 - accuracy: 0.7122 - val_loss: 0.7729 - val_accuracy: 0.7364\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8019 - accuracy: 0.7143 - val_loss: 0.7980 - val_accuracy: 0.7286\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7944 - accuracy: 0.7184 - val_loss: 0.7897 - val_accuracy: 0.7280\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7833 - accuracy: 0.7210 - val_loss: 0.7585 - val_accuracy: 0.7382\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7818 - accuracy: 0.7199 - val_loss: 0.7563 - val_accuracy: 0.7382\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7708 - accuracy: 0.7234 - val_loss: 0.7456 - val_accuracy: 0.7456\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7667 - accuracy: 0.7265 - val_loss: 0.7590 - val_accuracy: 0.7364\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7613 - accuracy: 0.7320 - val_loss: 0.7681 - val_accuracy: 0.7334\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7481 - accuracy: 0.7330 - val_loss: 0.7548 - val_accuracy: 0.7402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbR77LFSDYQC"
      },
      "source": [
        "### Baseline Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfsk6JVLDYQC",
        "outputId": "1836e9de-fc6d-4399-dbe4-fd5495972b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_loss, base_accuracy = model.evaluate(x_test, y_test)\n",
        "base_elapsed_time = end_t - start_t\n",
        "print(f\"Elapsed time (s): {base_elapsed_time:0.2f} (s)\")\n",
        "print(f'Baseline loss: {base_loss:0.3f}, accuracy: {base_accuracy:0.3f}%')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7810 - accuracy: 0.7349\n",
            "Elapsed time (s): 122.53 (s)\n",
            "Baseline loss: 0.781, accuracy: 0.735%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNnaQaBXDYQC"
      },
      "source": [
        "## Classical Hyperparameter Tuning tools\n",
        "\n",
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaM-0d4kDYQC"
      },
      "source": [
        "from kerastuner import HyperModel\n",
        "\n",
        "class CNNHyperModel(HyperModel):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(\n",
        "            Conv2D(\n",
        "                filters=16,\n",
        "                kernel_size=3,\n",
        "                activation=\"relu\",\n",
        "                input_shape=self.input_shape,\n",
        "            )\n",
        "        )\n",
        "        model.add(Conv2D(16, 3, activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=2))\n",
        "        model.add(\n",
        "            Dropout(\n",
        "                rate=hp.Float(\n",
        "                    \"dropout_1\", min_value=0.0, max_value=0.5, default=0.25, step=0.05,\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        model.add(\n",
        "            Conv2D(\n",
        "                filters=hp.Choice(\"num_filters\", values=[16, 32, 64, 128], default=32,),\n",
        "                activation=\"relu\",\n",
        "                kernel_size=3,\n",
        "            )\n",
        "        )\n",
        "        model.add(MaxPooling2D(pool_size=2))\n",
        "        model.add(\n",
        "            Dropout(\n",
        "                rate=hp.Float(\n",
        "                    \"dropout_2\", min_value=0.0, max_value=0.5, default=0.25, step=0.05,\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        model.add(Flatten())\n",
        "        model.add(\n",
        "            Dense(\n",
        "                units=hp.Int(\n",
        "                    \"units\", min_value=32, max_value=512, step=16, default=128\n",
        "                ),\n",
        "                activation=hp.Choice(\n",
        "                    \"dense_activation\",\n",
        "                    values=[\"relu\", \"tanh\", \"sigmoid\"],\n",
        "                    default=\"relu\",\n",
        "                ),\n",
        "            )\n",
        "        )\n",
        "        model.add(\n",
        "            Dropout(\n",
        "                rate=hp.Float(\n",
        "                    \"dropout_3\", min_value=0.0, max_value=0.5, default=0.25, step=0.05\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        model.add(Dense(self.num_classes, activation=\"softmax\"))\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(\n",
        "                hp.Float(\n",
        "                    \"learning_rate\",\n",
        "                    min_value=1e-4,\n",
        "                    max_value=1e-2,\n",
        "                    sampling=\"LOG\",\n",
        "                    default=1e-3,\n",
        "                )\n",
        "            ),\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hMiZaYADYQC"
      },
      "source": [
        "# Environmental Variables\n",
        "from pathlib import Path\n",
        "from kerastuner.tuners import BayesianOptimization, Hyperband, RandomSearch\n",
        "\n",
        "model = CNNHyperModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
        "\n",
        "output_dir = Path(\"./output/cifar10/\")\n",
        "project_name = \"simple_cnn_model_tuning\"\n",
        "HYPERBAND_MAX_EPOCHS = 25\n",
        "MAX_TRIALS = 20\n",
        "EXECUTION_PER_TRIAL = 2\n",
        "BAYESIAN_NUM_INITIAL_POINTS = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14lFQWh1DYQD"
      },
      "source": [
        "### Tuner definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGG8vWunDYQD"
      },
      "source": [
        "tuners = [\n",
        "    RandomSearch(\n",
        "        model,\n",
        "        objective=\"val_accuracy\",\n",
        "        seed=SEED,\n",
        "        max_trials=MAX_TRIALS,\n",
        "        executions_per_trial=EXECUTION_PER_TRIAL,\n",
        "        directory=f\"{output_dir}_random_search\",\n",
        "        project_name=project_name,\n",
        "    ),\n",
        "    Hyperband(\n",
        "        model,\n",
        "        max_epochs=HYPERBAND_MAX_EPOCHS,\n",
        "        objective=\"val_accuracy\",\n",
        "        seed=SEED,\n",
        "        executions_per_trial=EXECUTION_PER_TRIAL,\n",
        "        directory=f\"{output_dir}_hyperband\",\n",
        "        project_name=project_name,\n",
        "    ),\n",
        "    BayesianOptimization(\n",
        "        model,\n",
        "        objective='val_accuracy',\n",
        "        seed=SEED,\n",
        "        num_initial_points=BAYESIAN_NUM_INITIAL_POINTS,\n",
        "        max_trials=MAX_TRIALS,\n",
        "        directory=f\"{output_dir}_bayesian\",\n",
        "        project_name=project_name\n",
        "    )\n",
        "]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5VIsjhkDYQD"
      },
      "source": [
        "### Tuner Workflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh8d5EWXDYQE"
      },
      "source": [
        "def tuner_workflow(tuner, x_train, y_train, x_test, y_test):\n",
        "    tuner.search_space_summary()\n",
        "    search_start = time.time()\n",
        "    tuner.search(x_train, y_train, epochs=EPOCHS, validation_split=0.1)\n",
        "    search_end = time.time()\n",
        "    elapsed_time = search_end - search_start\n",
        "\n",
        "    # Show a summary of the search\n",
        "    tuner.results_summary()\n",
        "\n",
        "    # Retrieve the best model.\n",
        "    best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "    # Evaluate the best model.\n",
        "    loss, accuracy = best_model.evaluate(x_test, y_test)\n",
        "    return elapsed_time, loss, accuracy"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnAwstIPDYQE",
        "outputId": "83b86903-41f0-4aa1-a48c-3f1cb57b5081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = [[base_elapsed_time, base_loss, base_accuracy]]\n",
        "for tuner in tuners:\n",
        "    elapsed_time, loss, accuracy = tuner_workflow(\n",
        "        tuner, x_train, y_train, x_test, y_test\n",
        "    )\n",
        "    results.append([elapsed_time, loss, accuracy])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 01m 58s]\n",
            "val_accuracy: 0.7128000259399414\n",
            "\n",
            "Best val_accuracy So Far: 0.7638000249862671\n",
            "Total elapsed time: 00h 42m 13s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Results summary\n",
            "Results in output/cifar10_bayesian/simple_cnn_model_tuning\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.0\n",
            "num_filters: 128\n",
            "dropout_2: 0.5\n",
            "units: 512\n",
            "dense_activation: relu\n",
            "dropout_3: 0.2\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7638000249862671\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.30000000000000004\n",
            "num_filters: 128\n",
            "dropout_2: 0.2\n",
            "units: 512\n",
            "dense_activation: relu\n",
            "dropout_3: 0.2\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7580000162124634\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.15000000000000002\n",
            "num_filters: 128\n",
            "dropout_2: 0.5\n",
            "units: 512\n",
            "dense_activation: relu\n",
            "dropout_3: 0.0\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7563999891281128\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.0\n",
            "num_filters: 128\n",
            "dropout_2: 0.0\n",
            "units: 512\n",
            "dense_activation: relu\n",
            "dropout_3: 0.5\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7509999871253967\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.5\n",
            "num_filters: 128\n",
            "dropout_2: 0.5\n",
            "units: 512\n",
            "dense_activation: relu\n",
            "dropout_3: 0.0\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7495999932289124\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.5\n",
            "num_filters: 128\n",
            "dropout_2: 0.0\n",
            "units: 512\n",
            "dense_activation: relu\n",
            "dropout_3: 0.5\n",
            "learning_rate: 0.0001\n",
            "Score: 0.746399998664856\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.0\n",
            "num_filters: 128\n",
            "dropout_2: 0.5\n",
            "units: 176\n",
            "dense_activation: relu\n",
            "dropout_3: 0.0\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7459999918937683\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.35000000000000003\n",
            "num_filters: 128\n",
            "dropout_2: 0.1\n",
            "units: 256\n",
            "dense_activation: tanh\n",
            "dropout_3: 0.30000000000000004\n",
            "learning_rate: 0.00011942731780421024\n",
            "Score: 0.7314000129699707\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.0\n",
            "num_filters: 128\n",
            "dropout_2: 0.5\n",
            "units: 512\n",
            "dense_activation: sigmoid\n",
            "dropout_3: 0.0\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7311999797821045\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dropout_1: 0.0\n",
            "num_filters: 128\n",
            "dropout_2: 0.0\n",
            "units: 512\n",
            "dense_activation: relu\n",
            "dropout_3: 0.0\n",
            "learning_rate: 0.0001\n",
            "Score: 0.725600004196167\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7423 - accuracy: 0.7457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_PpiM81DYQE"
      },
      "source": [
        "# Save results\n",
        "import pickle\n",
        "with open('./output/tuners.pk', 'wb') as f:\n",
        "    pickle.dump(tuners, f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_neWZ2bGDYQE"
      },
      "source": [
        "## AI Driven Hyperparameter Tuning tools\n",
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXMg4nyoDYQF"
      },
      "source": [
        "def hypermodel_func(hyperparams, trial):\n",
        "    tf.random.set_seed(SEED)\n",
        "    model = keras.Sequential()\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            filters=8,\n",
        "            kernel_size=3,\n",
        "            activation='relu',\n",
        "            input_shape=INPUT_SHAPE\n",
        "        )\n",
        "    )\n",
        "    model.add(Conv2D(16, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(rate=hyperparams['dropout_1'][trial]))\n",
        "    model.add(Conv2D(filters=hyperparams['num_filters'][trial], kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(rate=hyperparams['dropout_2'][trial]))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(\n",
        "        units=hyperparams['units'][trial], \n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(Dropout(rate=hyperparams['dropout_3'][trial]))\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "    model.compile(\n",
        "            optimizer=keras.optimizers.Adam(hyperparams['learning_rate'][trial]),\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "    history = model.fit(x_train, y_train, epochs=EPOCHS, validation_split=0.1)\n",
        "    return model, history          "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hWdR9uXDYQF"
      },
      "source": [
        "### Hyperparams ranges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jbn2vPUDYQF",
        "outputId": "dbb822c1-55de-4809-e2d0-2638fa86e7c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from aisaratuners import aisara_keras_tuner as akt\n",
        "\n",
        "hyperparams = akt.Hp()\n",
        "hyperparams.numrange(name='dropout_1', min=0.0, max=0.5)\n",
        "hyperparams.numrange(name='num_filters', min=16, max=128)\n",
        "hyperparams.numrange(name='dropout_2', min=0.0, max=0.5)\n",
        "hyperparams.numrange(name='units', min=32, max=512)\n",
        "hyperparams.numrange(name='dropout_3', min=0.0, max=0.5)\n",
        "hyperparams.numrange(name='learning_rate', min=1e-4, max=1e-2, type='log')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B7WmDtaDYQF"
      },
      "source": [
        "### Tuner configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXkaatumDYQF"
      },
      "source": [
        "tuner = akt.HpOptimization(\n",
        "    hyperparams, \n",
        "    hypermodel_func, \n",
        "    ['val_accuracy', 'val_loss'], \n",
        "    ['max', 'min'], \n",
        "    num_trials=5, \n",
        "    rounds=3,\n",
        "    mode='p',\n",
        "    aisara_seed='fixed'\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwsZaBDtDYQF"
      },
      "source": [
        "### Tuning job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK-54AtDDYQG",
        "outputId": "61925d17-8a1a-41a7-d622-f5c092ffa6e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "start_t = time.time()\n",
        "tuner.run_opti()\n",
        "end_t = time.time()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mFor commercial use, you can obtain our API from https://rapidapi.com/aisara-technology-aisara-technology-default/api/aisara-hyperparameter-tuning\n",
            "If you are a private user, set the mode parameter in HpOptimization class to \"p\".\n",
            "\u001b[0m\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aisaratuners/aisara_keras_tuner.py:175: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
            "\n",
            "\u001b[1m\u001b[94mRound-1:\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-1:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.7004 - accuracy: 0.3674 - val_loss: 1.4336 - val_accuracy: 0.4648\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4007 - accuracy: 0.4986 - val_loss: 1.3410 - val_accuracy: 0.5162\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2905 - accuracy: 0.5421 - val_loss: 1.2949 - val_accuracy: 0.5520\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.2217 - accuracy: 0.5666 - val_loss: 1.2923 - val_accuracy: 0.5440\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1814 - accuracy: 0.5808 - val_loss: 1.2745 - val_accuracy: 0.5550\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1448 - accuracy: 0.5956 - val_loss: 1.2175 - val_accuracy: 0.5780\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.1259 - accuracy: 0.6017 - val_loss: 1.2696 - val_accuracy: 0.5630\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0990 - accuracy: 0.6135 - val_loss: 1.2793 - val_accuracy: 0.5684\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0842 - accuracy: 0.6188 - val_loss: 1.2565 - val_accuracy: 0.5610\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0599 - accuracy: 0.6271 - val_loss: 1.2299 - val_accuracy: 0.5820\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0493 - accuracy: 0.6341 - val_loss: 1.2317 - val_accuracy: 0.5846\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.0403 - accuracy: 0.6355 - val_loss: 1.3224 - val_accuracy: 0.5442\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0221 - accuracy: 0.6412 - val_loss: 1.2395 - val_accuracy: 0.5798\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0158 - accuracy: 0.6445 - val_loss: 1.2313 - val_accuracy: 0.5908\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0047 - accuracy: 0.6477 - val_loss: 1.2104 - val_accuracy: 0.5920\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9877 - accuracy: 0.6542 - val_loss: 1.2819 - val_accuracy: 0.5712\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9875 - accuracy: 0.6554 - val_loss: 1.2689 - val_accuracy: 0.5806\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9785 - accuracy: 0.6567 - val_loss: 1.2745 - val_accuracy: 0.5850\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9576 - accuracy: 0.6647 - val_loss: 1.2606 - val_accuracy: 0.5938\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9574 - accuracy: 0.6653 - val_loss: 1.2589 - val_accuracy: 0.5784\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9488 - accuracy: 0.6680 - val_loss: 1.2801 - val_accuracy: 0.5860\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9506 - accuracy: 0.6674 - val_loss: 1.2965 - val_accuracy: 0.5830\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9383 - accuracy: 0.6716 - val_loss: 1.3107 - val_accuracy: 0.5700\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9271 - accuracy: 0.6730 - val_loss: 1.2825 - val_accuracy: 0.5930\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9268 - accuracy: 0.6746 - val_loss: 1.3294 - val_accuracy: 0.5720\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-2:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.5537 - accuracy: 0.4342 - val_loss: 1.2492 - val_accuracy: 0.5568\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.1745 - accuracy: 0.5846 - val_loss: 1.0403 - val_accuracy: 0.6344\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9944 - accuracy: 0.6517 - val_loss: 1.0004 - val_accuracy: 0.6512\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8708 - accuracy: 0.6958 - val_loss: 0.8738 - val_accuracy: 0.7048\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7817 - accuracy: 0.7283 - val_loss: 0.8607 - val_accuracy: 0.6972\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7089 - accuracy: 0.7526 - val_loss: 0.8591 - val_accuracy: 0.7080\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6396 - accuracy: 0.7763 - val_loss: 0.8454 - val_accuracy: 0.7174\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5842 - accuracy: 0.7956 - val_loss: 0.9405 - val_accuracy: 0.7040\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5340 - accuracy: 0.8122 - val_loss: 0.8798 - val_accuracy: 0.7122\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4794 - accuracy: 0.8319 - val_loss: 0.9096 - val_accuracy: 0.7172\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4373 - accuracy: 0.8459 - val_loss: 0.9400 - val_accuracy: 0.7148\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3908 - accuracy: 0.8614 - val_loss: 1.0144 - val_accuracy: 0.7132\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3468 - accuracy: 0.8788 - val_loss: 1.1020 - val_accuracy: 0.7052\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3084 - accuracy: 0.8905 - val_loss: 1.1779 - val_accuracy: 0.6988\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2753 - accuracy: 0.9014 - val_loss: 1.2502 - val_accuracy: 0.6972\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2433 - accuracy: 0.9126 - val_loss: 1.3536 - val_accuracy: 0.6930\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2146 - accuracy: 0.9227 - val_loss: 1.4155 - val_accuracy: 0.7016\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1877 - accuracy: 0.9322 - val_loss: 1.5486 - val_accuracy: 0.7002\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1703 - accuracy: 0.9371 - val_loss: 1.6036 - val_accuracy: 0.6968\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1560 - accuracy: 0.9440 - val_loss: 1.7438 - val_accuracy: 0.6914\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1482 - accuracy: 0.9464 - val_loss: 1.8980 - val_accuracy: 0.6920\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1391 - accuracy: 0.9499 - val_loss: 1.9471 - val_accuracy: 0.6760\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1172 - accuracy: 0.9587 - val_loss: 2.0161 - val_accuracy: 0.6936\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1184 - accuracy: 0.9569 - val_loss: 2.0435 - val_accuracy: 0.6904\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1203 - accuracy: 0.9574 - val_loss: 2.1596 - val_accuracy: 0.6840\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-3:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.6865 - accuracy: 0.3860 - val_loss: 1.4486 - val_accuracy: 0.4760\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.3668 - accuracy: 0.5155 - val_loss: 1.2554 - val_accuracy: 0.5620\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.2166 - accuracy: 0.5719 - val_loss: 1.1950 - val_accuracy: 0.5862\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1111 - accuracy: 0.6099 - val_loss: 1.0723 - val_accuracy: 0.6256\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0263 - accuracy: 0.6415 - val_loss: 1.0428 - val_accuracy: 0.6356\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9561 - accuracy: 0.6665 - val_loss: 0.9854 - val_accuracy: 0.6620\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8968 - accuracy: 0.6894 - val_loss: 0.9299 - val_accuracy: 0.6772\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8436 - accuracy: 0.7069 - val_loss: 0.9546 - val_accuracy: 0.6716\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7918 - accuracy: 0.7253 - val_loss: 0.8805 - val_accuracy: 0.6958\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7445 - accuracy: 0.7423 - val_loss: 0.8676 - val_accuracy: 0.7034\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7009 - accuracy: 0.7604 - val_loss: 0.8394 - val_accuracy: 0.7124\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6547 - accuracy: 0.7746 - val_loss: 0.8277 - val_accuracy: 0.7190\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6082 - accuracy: 0.7916 - val_loss: 0.8206 - val_accuracy: 0.7212\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5651 - accuracy: 0.8100 - val_loss: 0.8484 - val_accuracy: 0.7126\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5255 - accuracy: 0.8232 - val_loss: 0.8309 - val_accuracy: 0.7186\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4835 - accuracy: 0.8388 - val_loss: 0.8700 - val_accuracy: 0.7126\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4402 - accuracy: 0.8538 - val_loss: 0.8210 - val_accuracy: 0.7274\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3992 - accuracy: 0.8686 - val_loss: 0.8495 - val_accuracy: 0.7284\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3591 - accuracy: 0.8833 - val_loss: 0.8905 - val_accuracy: 0.7186\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3200 - accuracy: 0.8977 - val_loss: 0.8957 - val_accuracy: 0.7238\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2808 - accuracy: 0.9114 - val_loss: 0.9495 - val_accuracy: 0.7186\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2462 - accuracy: 0.9237 - val_loss: 0.9606 - val_accuracy: 0.7204\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2081 - accuracy: 0.9378 - val_loss: 0.9894 - val_accuracy: 0.7264\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1760 - accuracy: 0.9485 - val_loss: 1.0662 - val_accuracy: 0.7170\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1458 - accuracy: 0.9593 - val_loss: 1.1024 - val_accuracy: 0.7138\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-4:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5644 - accuracy: 0.4315 - val_loss: 1.3251 - val_accuracy: 0.5266\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1821 - accuracy: 0.5840 - val_loss: 1.0551 - val_accuracy: 0.6354\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9941 - accuracy: 0.6507 - val_loss: 0.9404 - val_accuracy: 0.6718\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8639 - accuracy: 0.6971 - val_loss: 0.8700 - val_accuracy: 0.6952\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7611 - accuracy: 0.7345 - val_loss: 0.8525 - val_accuracy: 0.7026\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6721 - accuracy: 0.7690 - val_loss: 0.8277 - val_accuracy: 0.7262\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5829 - accuracy: 0.7988 - val_loss: 0.7822 - val_accuracy: 0.7378\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4992 - accuracy: 0.8297 - val_loss: 0.8866 - val_accuracy: 0.7138\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4209 - accuracy: 0.8580 - val_loss: 0.8216 - val_accuracy: 0.7324\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3465 - accuracy: 0.8838 - val_loss: 0.8512 - val_accuracy: 0.7404\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2775 - accuracy: 0.9078 - val_loss: 0.9118 - val_accuracy: 0.7420\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2109 - accuracy: 0.9324 - val_loss: 0.9933 - val_accuracy: 0.7312\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1591 - accuracy: 0.9494 - val_loss: 1.0799 - val_accuracy: 0.7324\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1156 - accuracy: 0.9644 - val_loss: 1.1771 - val_accuracy: 0.7302\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9739 - val_loss: 1.2708 - val_accuracy: 0.7304\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0747 - accuracy: 0.9770 - val_loss: 1.3274 - val_accuracy: 0.7370\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0616 - accuracy: 0.9817 - val_loss: 1.4059 - val_accuracy: 0.7306\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0525 - accuracy: 0.9839 - val_loss: 1.4694 - val_accuracy: 0.7336\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 1.6401 - val_accuracy: 0.7292\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0456 - accuracy: 0.9850 - val_loss: 1.7046 - val_accuracy: 0.7184\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 1.6854 - val_accuracy: 0.7326\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0394 - accuracy: 0.9876 - val_loss: 1.7554 - val_accuracy: 0.7296\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 1.8185 - val_accuracy: 0.7294\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 1.7431 - val_accuracy: 0.7342\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 1.8172 - val_accuracy: 0.7324\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-5:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.4344 - accuracy: 0.4768 - val_loss: 1.2139 - val_accuracy: 0.5632\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0538 - accuracy: 0.6278 - val_loss: 0.9505 - val_accuracy: 0.6728\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8829 - accuracy: 0.6922 - val_loss: 0.9409 - val_accuracy: 0.6810\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7572 - accuracy: 0.7326 - val_loss: 0.8969 - val_accuracy: 0.7016\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6408 - accuracy: 0.7728 - val_loss: 0.9493 - val_accuracy: 0.6730\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5474 - accuracy: 0.8075 - val_loss: 1.0676 - val_accuracy: 0.6858\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4609 - accuracy: 0.8368 - val_loss: 1.0946 - val_accuracy: 0.6892\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3883 - accuracy: 0.8625 - val_loss: 1.2376 - val_accuracy: 0.6800\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3321 - accuracy: 0.8828 - val_loss: 1.5417 - val_accuracy: 0.6524\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2874 - accuracy: 0.8986 - val_loss: 1.4513 - val_accuracy: 0.6638\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2523 - accuracy: 0.9131 - val_loss: 1.5983 - val_accuracy: 0.6724\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2279 - accuracy: 0.9219 - val_loss: 1.8654 - val_accuracy: 0.6654\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2134 - accuracy: 0.9266 - val_loss: 1.9214 - val_accuracy: 0.6632\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1999 - accuracy: 0.9316 - val_loss: 2.0727 - val_accuracy: 0.6562\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1945 - accuracy: 0.9347 - val_loss: 2.1982 - val_accuracy: 0.6712\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1754 - accuracy: 0.9426 - val_loss: 2.2891 - val_accuracy: 0.6624\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1781 - accuracy: 0.9417 - val_loss: 2.3401 - val_accuracy: 0.6570\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1615 - accuracy: 0.9466 - val_loss: 2.3609 - val_accuracy: 0.6666\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1815 - accuracy: 0.9442 - val_loss: 2.4869 - val_accuracy: 0.6538\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1613 - accuracy: 0.9493 - val_loss: 2.7460 - val_accuracy: 0.6492\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1551 - accuracy: 0.9506 - val_loss: 2.7499 - val_accuracy: 0.6512\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1519 - accuracy: 0.9527 - val_loss: 2.7525 - val_accuracy: 0.6628\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1521 - accuracy: 0.9524 - val_loss: 2.7691 - val_accuracy: 0.6660\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1504 - accuracy: 0.9534 - val_loss: 2.7640 - val_accuracy: 0.6612\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1505 - accuracy: 0.9555 - val_loss: 3.0635 - val_accuracy: 0.6540\n",
            "\u001b[1m\n",
            "\n",
            "search space boundaries:\n",
            "\u001b[0m      dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate\n",
            "min        0.0           16        0.0     32        0.0         0.0001\n",
            "max        0.5          128        0.5    512        0.5         0.0100 \n",
            "\n",
            "\u001b[1mhyperparameters combinations (lHC):\n",
            "\u001b[0m  dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate\n",
            "         0           72          0    176          0       0.006310\n",
            "         0           50          0     80          0       0.001000\n",
            "         0           94          0    464          0       0.000158\n",
            "         0          117          0    272          0       0.000398\n",
            "         0           27          0    368          0       0.002512 \n",
            "\n",
            "\u001b[1mmodels results:\n",
            "\u001b[0m\u001b[0m  dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate      loss  accuracy  val_loss  val_accuracy\n",
            "         0           72          0    176          0       0.006310  0.926804  0.674622  1.329360        0.5720\n",
            "         0           50          0     80          0       0.001000  0.120283  0.957378  2.159582        0.6840\n",
            "         0           94          0    464          0       0.000158  0.145767  0.959267  1.102425        0.7138\n",
            "         0          117          0    272          0       0.000398  0.035043  0.988222  1.817225        0.7324\n",
            "         0           27          0    368          0       0.002512  0.150502  0.955511  3.063491        0.6540\n",
            "\u001b[1m\n",
            "working on the creation of reduced search space boundaries for the next round, pls wait this might take some time\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[95mAisara_max_error Run:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.7373 - accuracy: 0.3683 - val_loss: 1.5252 - val_accuracy: 0.4454\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.4334 - accuracy: 0.4870 - val_loss: 1.3296 - val_accuracy: 0.5292\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.2951 - accuracy: 0.5434 - val_loss: 1.2573 - val_accuracy: 0.5630\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1996 - accuracy: 0.5822 - val_loss: 1.1440 - val_accuracy: 0.6014\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1164 - accuracy: 0.6092 - val_loss: 1.1174 - val_accuracy: 0.6072\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0451 - accuracy: 0.6376 - val_loss: 1.0499 - val_accuracy: 0.6352\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9860 - accuracy: 0.6591 - val_loss: 0.9886 - val_accuracy: 0.6572\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9341 - accuracy: 0.6756 - val_loss: 0.9878 - val_accuracy: 0.6620\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8865 - accuracy: 0.6937 - val_loss: 0.9503 - val_accuracy: 0.6698\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8460 - accuracy: 0.7092 - val_loss: 0.9175 - val_accuracy: 0.6844\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8093 - accuracy: 0.7230 - val_loss: 0.8820 - val_accuracy: 0.6988\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7741 - accuracy: 0.7343 - val_loss: 0.8875 - val_accuracy: 0.6940\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.7364 - accuracy: 0.7463 - val_loss: 0.8655 - val_accuracy: 0.7102\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7032 - accuracy: 0.7577 - val_loss: 0.8870 - val_accuracy: 0.7004\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6707 - accuracy: 0.7695 - val_loss: 0.8563 - val_accuracy: 0.7098\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6374 - accuracy: 0.7816 - val_loss: 0.8724 - val_accuracy: 0.7030\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6040 - accuracy: 0.7955 - val_loss: 0.8175 - val_accuracy: 0.7250\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5711 - accuracy: 0.8062 - val_loss: 0.8304 - val_accuracy: 0.7208\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5389 - accuracy: 0.8183 - val_loss: 0.8478 - val_accuracy: 0.7164\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5071 - accuracy: 0.8293 - val_loss: 0.8328 - val_accuracy: 0.7224\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4755 - accuracy: 0.8405 - val_loss: 0.8575 - val_accuracy: 0.7286\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4444 - accuracy: 0.8511 - val_loss: 0.8428 - val_accuracy: 0.7266\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4122 - accuracy: 0.8651 - val_loss: 0.8432 - val_accuracy: 0.7334\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3798 - accuracy: 0.8768 - val_loss: 0.8663 - val_accuracy: 0.7308\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3520 - accuracy: 0.8861 - val_loss: 0.9013 - val_accuracy: 0.7250\n",
            "\n",
            "\u001b[1m\u001b[94mRound-2:\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-1:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5998 - accuracy: 0.4186 - val_loss: 1.3612 - val_accuracy: 0.5120\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.2284 - accuracy: 0.5666 - val_loss: 1.0975 - val_accuracy: 0.6112\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0541 - accuracy: 0.6302 - val_loss: 1.0116 - val_accuracy: 0.6460\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9265 - accuracy: 0.6774 - val_loss: 0.9177 - val_accuracy: 0.6856\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8272 - accuracy: 0.7112 - val_loss: 0.8862 - val_accuracy: 0.6902\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7461 - accuracy: 0.7409 - val_loss: 0.8521 - val_accuracy: 0.7062\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6659 - accuracy: 0.7696 - val_loss: 0.7976 - val_accuracy: 0.7252\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5928 - accuracy: 0.7957 - val_loss: 0.8368 - val_accuracy: 0.7214\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5211 - accuracy: 0.8214 - val_loss: 0.8313 - val_accuracy: 0.7238\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4506 - accuracy: 0.8454 - val_loss: 0.8286 - val_accuracy: 0.7288\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3841 - accuracy: 0.8692 - val_loss: 0.8562 - val_accuracy: 0.7348\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3132 - accuracy: 0.8942 - val_loss: 0.9064 - val_accuracy: 0.7256\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2507 - accuracy: 0.9177 - val_loss: 0.9689 - val_accuracy: 0.7220\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1958 - accuracy: 0.9370 - val_loss: 1.0589 - val_accuracy: 0.7176\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1500 - accuracy: 0.9534 - val_loss: 1.2046 - val_accuracy: 0.7184\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1156 - accuracy: 0.9653 - val_loss: 1.2542 - val_accuracy: 0.7094\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0914 - accuracy: 0.9719 - val_loss: 1.3621 - val_accuracy: 0.7082\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0686 - accuracy: 0.9801 - val_loss: 1.4854 - val_accuracy: 0.7046\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0614 - accuracy: 0.9817 - val_loss: 1.5490 - val_accuracy: 0.7148\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0546 - accuracy: 0.9842 - val_loss: 1.6463 - val_accuracy: 0.7092\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0467 - accuracy: 0.9859 - val_loss: 1.6931 - val_accuracy: 0.7106\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0472 - accuracy: 0.9853 - val_loss: 1.7808 - val_accuracy: 0.7128\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0423 - accuracy: 0.9871 - val_loss: 1.8602 - val_accuracy: 0.6966\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0404 - accuracy: 0.9868 - val_loss: 1.8605 - val_accuracy: 0.7102\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 1.9267 - val_accuracy: 0.7102\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-2:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5771 - accuracy: 0.4284 - val_loss: 1.3184 - val_accuracy: 0.5280\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.2054 - accuracy: 0.5746 - val_loss: 1.0850 - val_accuracy: 0.6154\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0190 - accuracy: 0.6439 - val_loss: 0.9876 - val_accuracy: 0.6512\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8899 - accuracy: 0.6905 - val_loss: 0.8937 - val_accuracy: 0.6890\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7851 - accuracy: 0.7253 - val_loss: 0.8886 - val_accuracy: 0.6898\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6894 - accuracy: 0.7617 - val_loss: 0.8299 - val_accuracy: 0.7180\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5976 - accuracy: 0.7930 - val_loss: 0.8035 - val_accuracy: 0.7326\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5113 - accuracy: 0.8264 - val_loss: 0.8518 - val_accuracy: 0.7202\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4272 - accuracy: 0.8554 - val_loss: 0.8449 - val_accuracy: 0.7366\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3443 - accuracy: 0.8848 - val_loss: 0.8937 - val_accuracy: 0.7374\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2721 - accuracy: 0.9105 - val_loss: 0.9061 - val_accuracy: 0.7338\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2010 - accuracy: 0.9345 - val_loss: 0.9778 - val_accuracy: 0.7374\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1446 - accuracy: 0.9553 - val_loss: 1.0762 - val_accuracy: 0.7352\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1079 - accuracy: 0.9666 - val_loss: 1.1930 - val_accuracy: 0.7300\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0782 - accuracy: 0.9769 - val_loss: 1.3213 - val_accuracy: 0.7278\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0646 - accuracy: 0.9809 - val_loss: 1.3765 - val_accuracy: 0.7304\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 1.5046 - val_accuracy: 0.7288\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0476 - accuracy: 0.9860 - val_loss: 1.5403 - val_accuracy: 0.7232\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0455 - accuracy: 0.9856 - val_loss: 1.6180 - val_accuracy: 0.7298\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0386 - accuracy: 0.9876 - val_loss: 1.7686 - val_accuracy: 0.7256\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 1.8227 - val_accuracy: 0.7198\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 1.9224 - val_accuracy: 0.7210\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 1.8294 - val_accuracy: 0.7212\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 1.9804 - val_accuracy: 0.7232\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 1.9288 - val_accuracy: 0.7278\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-3:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6427 - accuracy: 0.3977 - val_loss: 1.4307 - val_accuracy: 0.4850\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.3212 - accuracy: 0.5294 - val_loss: 1.2015 - val_accuracy: 0.5758\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1782 - accuracy: 0.5822 - val_loss: 1.1797 - val_accuracy: 0.5862\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0661 - accuracy: 0.6239 - val_loss: 1.0424 - val_accuracy: 0.6396\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9763 - accuracy: 0.6572 - val_loss: 1.0227 - val_accuracy: 0.6394\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8998 - accuracy: 0.6858 - val_loss: 0.9521 - val_accuracy: 0.6742\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8298 - accuracy: 0.7125 - val_loss: 0.9119 - val_accuracy: 0.6816\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7685 - accuracy: 0.7318 - val_loss: 0.9158 - val_accuracy: 0.6854\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7103 - accuracy: 0.7538 - val_loss: 0.9006 - val_accuracy: 0.6898\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6557 - accuracy: 0.7730 - val_loss: 0.8462 - val_accuracy: 0.7042\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6028 - accuracy: 0.7909 - val_loss: 0.8557 - val_accuracy: 0.7086\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5477 - accuracy: 0.8112 - val_loss: 0.8860 - val_accuracy: 0.7078\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4962 - accuracy: 0.8288 - val_loss: 0.8750 - val_accuracy: 0.7116\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4425 - accuracy: 0.8482 - val_loss: 0.9301 - val_accuracy: 0.7040\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3943 - accuracy: 0.8655 - val_loss: 0.9474 - val_accuracy: 0.7070\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3454 - accuracy: 0.8836 - val_loss: 0.9923 - val_accuracy: 0.7010\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2991 - accuracy: 0.8999 - val_loss: 1.0066 - val_accuracy: 0.7084\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2564 - accuracy: 0.9139 - val_loss: 1.1057 - val_accuracy: 0.7006\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2130 - accuracy: 0.9299 - val_loss: 1.1541 - val_accuracy: 0.7076\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1799 - accuracy: 0.9422 - val_loss: 1.2511 - val_accuracy: 0.7024\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1475 - accuracy: 0.9528 - val_loss: 1.3225 - val_accuracy: 0.6980\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1199 - accuracy: 0.9623 - val_loss: 1.4316 - val_accuracy: 0.6958\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1029 - accuracy: 0.9682 - val_loss: 1.5239 - val_accuracy: 0.6912\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9720 - val_loss: 1.5544 - val_accuracy: 0.7018\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0786 - accuracy: 0.9762 - val_loss: 1.6273 - val_accuracy: 0.7010\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-4:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.5833 - accuracy: 0.4252 - val_loss: 1.3712 - val_accuracy: 0.5054\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.2410 - accuracy: 0.5616 - val_loss: 1.1083 - val_accuracy: 0.6120\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0763 - accuracy: 0.6220 - val_loss: 1.0195 - val_accuracy: 0.6396\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9676 - accuracy: 0.6636 - val_loss: 0.9407 - val_accuracy: 0.6754\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8804 - accuracy: 0.6928 - val_loss: 0.9384 - val_accuracy: 0.6688\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8115 - accuracy: 0.7200 - val_loss: 0.8688 - val_accuracy: 0.7022\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7452 - accuracy: 0.7430 - val_loss: 0.8219 - val_accuracy: 0.7188\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6824 - accuracy: 0.7622 - val_loss: 0.8330 - val_accuracy: 0.7156\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6255 - accuracy: 0.7837 - val_loss: 0.7913 - val_accuracy: 0.7226\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5672 - accuracy: 0.8040 - val_loss: 0.8284 - val_accuracy: 0.7262\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5150 - accuracy: 0.8218 - val_loss: 0.8013 - val_accuracy: 0.7312\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4578 - accuracy: 0.8408 - val_loss: 0.8083 - val_accuracy: 0.7340\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4017 - accuracy: 0.8623 - val_loss: 0.8439 - val_accuracy: 0.7338\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3517 - accuracy: 0.8811 - val_loss: 0.9079 - val_accuracy: 0.7324\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3067 - accuracy: 0.8973 - val_loss: 0.9411 - val_accuracy: 0.7302\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2568 - accuracy: 0.9151 - val_loss: 0.9843 - val_accuracy: 0.7200\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2154 - accuracy: 0.9291 - val_loss: 1.0900 - val_accuracy: 0.7272\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1814 - accuracy: 0.9404 - val_loss: 1.1260 - val_accuracy: 0.7206\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1426 - accuracy: 0.9554 - val_loss: 1.2266 - val_accuracy: 0.7222\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1208 - accuracy: 0.9620 - val_loss: 1.3283 - val_accuracy: 0.7158\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1009 - accuracy: 0.9679 - val_loss: 1.4023 - val_accuracy: 0.7260\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9742 - val_loss: 1.5070 - val_accuracy: 0.7178\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0757 - accuracy: 0.9755 - val_loss: 1.5565 - val_accuracy: 0.7186\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0619 - accuracy: 0.9800 - val_loss: 1.5965 - val_accuracy: 0.7176\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0587 - accuracy: 0.9814 - val_loss: 1.6427 - val_accuracy: 0.7216\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-5:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5596 - accuracy: 0.4342 - val_loss: 1.3134 - val_accuracy: 0.5312\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1857 - accuracy: 0.5835 - val_loss: 1.0500 - val_accuracy: 0.6344\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0023 - accuracy: 0.6468 - val_loss: 0.9407 - val_accuracy: 0.6708\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8758 - accuracy: 0.6936 - val_loss: 0.8609 - val_accuracy: 0.7032\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7731 - accuracy: 0.7313 - val_loss: 0.8491 - val_accuracy: 0.7060\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6897 - accuracy: 0.7625 - val_loss: 0.8009 - val_accuracy: 0.7314\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6030 - accuracy: 0.7928 - val_loss: 0.7661 - val_accuracy: 0.7420\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5248 - accuracy: 0.8189 - val_loss: 0.8401 - val_accuracy: 0.7240\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4483 - accuracy: 0.8466 - val_loss: 0.7906 - val_accuracy: 0.7426\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3731 - accuracy: 0.8731 - val_loss: 0.8194 - val_accuracy: 0.7434\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3041 - accuracy: 0.8991 - val_loss: 0.8575 - val_accuracy: 0.7510\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2356 - accuracy: 0.9218 - val_loss: 0.9563 - val_accuracy: 0.7304\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1811 - accuracy: 0.9415 - val_loss: 1.0296 - val_accuracy: 0.7330\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1322 - accuracy: 0.9587 - val_loss: 1.1827 - val_accuracy: 0.7300\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1001 - accuracy: 0.9697 - val_loss: 1.2268 - val_accuracy: 0.7280\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0788 - accuracy: 0.9762 - val_loss: 1.2771 - val_accuracy: 0.7310\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0668 - accuracy: 0.9792 - val_loss: 1.3819 - val_accuracy: 0.7262\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0525 - accuracy: 0.9840 - val_loss: 1.4329 - val_accuracy: 0.7358\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 1.5612 - val_accuracy: 0.7290\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 1.6036 - val_accuracy: 0.7298\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0424 - accuracy: 0.9869 - val_loss: 1.6483 - val_accuracy: 0.7340\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0363 - accuracy: 0.9886 - val_loss: 1.7896 - val_accuracy: 0.7168\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 1.8230 - val_accuracy: 0.7110\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0383 - accuracy: 0.9875 - val_loss: 1.7555 - val_accuracy: 0.7288\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 1.7727 - val_accuracy: 0.7276\n",
            "\u001b[1m\n",
            "\n",
            "search space boundaries:\n",
            "\u001b[0m      dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate\n",
            "min          0           17          0    214          0       0.000378\n",
            "max          0          128          0    330          0       0.000420 \n",
            "\n",
            "\u001b[1mhyperparameters combinations (lHC):\n",
            "\u001b[0m  dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate\n",
            "         0           72          0    272          0       0.000382\n",
            "         0           95          0    318          0       0.000415\n",
            "         0           28          0    295          0       0.000390\n",
            "         0           50          0    226          0       0.000398\n",
            "         0          117          0    249          0       0.000407 \n",
            "\n",
            "\u001b[1mmodels results:\n",
            "\u001b[0m\u001b[0m  dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate      loss  accuracy  val_loss  val_accuracy\n",
            "         0           72          0    272          0       0.000382  0.035006  0.989000  1.926694        0.7102\n",
            "         0           95          0    318          0       0.000415  0.031315  0.989978  1.928836        0.7278\n",
            "         0           28          0    295          0       0.000390  0.078584  0.976222  1.627348        0.7010\n",
            "         0           50          0    226          0       0.000398  0.058705  0.981444  1.642681        0.7216\n",
            "         0          117          0    249          0       0.000407  0.030775  0.990067  1.772696        0.7276\n",
            "\u001b[1m\n",
            "working on the creation of reduced search space boundaries for the next round, pls wait this might take some time\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[95mAisara_max_error Run:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.6074 - accuracy: 0.4136 - val_loss: 1.3808 - val_accuracy: 0.4990\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.2716 - accuracy: 0.5481 - val_loss: 1.1505 - val_accuracy: 0.5948\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.1214 - accuracy: 0.6056 - val_loss: 1.0995 - val_accuracy: 0.6128\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.0060 - accuracy: 0.6482 - val_loss: 0.9667 - val_accuracy: 0.6602\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.9213 - accuracy: 0.6778 - val_loss: 0.9576 - val_accuracy: 0.6696\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.8538 - accuracy: 0.7019 - val_loss: 0.9079 - val_accuracy: 0.6896\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7878 - accuracy: 0.7273 - val_loss: 0.8625 - val_accuracy: 0.6948\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7297 - accuracy: 0.7448 - val_loss: 0.8983 - val_accuracy: 0.6902\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6736 - accuracy: 0.7681 - val_loss: 0.8407 - val_accuracy: 0.7124\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.6212 - accuracy: 0.7865 - val_loss: 0.8347 - val_accuracy: 0.7178\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5703 - accuracy: 0.8050 - val_loss: 0.8522 - val_accuracy: 0.7164\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5182 - accuracy: 0.8210 - val_loss: 0.8536 - val_accuracy: 0.7226\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4672 - accuracy: 0.8383 - val_loss: 0.8848 - val_accuracy: 0.7144\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.4212 - accuracy: 0.8562 - val_loss: 0.9131 - val_accuracy: 0.7166\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3763 - accuracy: 0.8719 - val_loss: 0.9775 - val_accuracy: 0.7106\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3318 - accuracy: 0.8885 - val_loss: 1.0229 - val_accuracy: 0.7084\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2887 - accuracy: 0.9018 - val_loss: 1.0079 - val_accuracy: 0.7216\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2503 - accuracy: 0.9171 - val_loss: 1.0945 - val_accuracy: 0.7096\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2132 - accuracy: 0.9284 - val_loss: 1.1521 - val_accuracy: 0.7124\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1819 - accuracy: 0.9399 - val_loss: 1.2787 - val_accuracy: 0.7038\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1537 - accuracy: 0.9485 - val_loss: 1.3414 - val_accuracy: 0.7168\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1272 - accuracy: 0.9586 - val_loss: 1.4997 - val_accuracy: 0.6988\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1131 - accuracy: 0.9627 - val_loss: 1.4844 - val_accuracy: 0.7068\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0938 - accuracy: 0.9701 - val_loss: 1.6370 - val_accuracy: 0.7016\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9734 - val_loss: 1.7063 - val_accuracy: 0.7022\n",
            "\n",
            "\u001b[1m\u001b[94mRound-3:\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-1:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5662 - accuracy: 0.4322 - val_loss: 1.3252 - val_accuracy: 0.5240\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1782 - accuracy: 0.5863 - val_loss: 1.0463 - val_accuracy: 0.6316\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9851 - accuracy: 0.6530 - val_loss: 0.9354 - val_accuracy: 0.6740\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8524 - accuracy: 0.7010 - val_loss: 0.8492 - val_accuracy: 0.7106\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7472 - accuracy: 0.7396 - val_loss: 0.8360 - val_accuracy: 0.7030\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6584 - accuracy: 0.7715 - val_loss: 0.8282 - val_accuracy: 0.7178\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5648 - accuracy: 0.8039 - val_loss: 0.7657 - val_accuracy: 0.7366\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4800 - accuracy: 0.8361 - val_loss: 0.8473 - val_accuracy: 0.7218\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3968 - accuracy: 0.8658 - val_loss: 0.8402 - val_accuracy: 0.7334\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3178 - accuracy: 0.8941 - val_loss: 0.8643 - val_accuracy: 0.7386\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2457 - accuracy: 0.9199 - val_loss: 0.9034 - val_accuracy: 0.7396\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1786 - accuracy: 0.9424 - val_loss: 0.9643 - val_accuracy: 0.7450\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1287 - accuracy: 0.9598 - val_loss: 1.0837 - val_accuracy: 0.7354\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0941 - accuracy: 0.9712 - val_loss: 1.1757 - val_accuracy: 0.7384\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0738 - accuracy: 0.9777 - val_loss: 1.2412 - val_accuracy: 0.7460\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0561 - accuracy: 0.9832 - val_loss: 1.3331 - val_accuracy: 0.7340\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0552 - accuracy: 0.9836 - val_loss: 1.4106 - val_accuracy: 0.7326\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 1.4185 - val_accuracy: 0.7402\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 1.6878 - val_accuracy: 0.7272\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0379 - accuracy: 0.9886 - val_loss: 1.5746 - val_accuracy: 0.7218\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0377 - accuracy: 0.9879 - val_loss: 1.7295 - val_accuracy: 0.7288\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 1.8608 - val_accuracy: 0.7156\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 1.7861 - val_accuracy: 0.7294\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 1.8028 - val_accuracy: 0.7196\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 1.8091 - val_accuracy: 0.7332\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-2:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5546 - accuracy: 0.4367 - val_loss: 1.3215 - val_accuracy: 0.5232\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1758 - accuracy: 0.5859 - val_loss: 1.0433 - val_accuracy: 0.6374\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9980 - accuracy: 0.6486 - val_loss: 0.9524 - val_accuracy: 0.6638\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8773 - accuracy: 0.6934 - val_loss: 0.8818 - val_accuracy: 0.6986\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7734 - accuracy: 0.7297 - val_loss: 0.8669 - val_accuracy: 0.6906\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6863 - accuracy: 0.7639 - val_loss: 0.8187 - val_accuracy: 0.7190\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5957 - accuracy: 0.7959 - val_loss: 0.7759 - val_accuracy: 0.7378\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5104 - accuracy: 0.8251 - val_loss: 0.8357 - val_accuracy: 0.7242\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4306 - accuracy: 0.8535 - val_loss: 0.8265 - val_accuracy: 0.7316\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3503 - accuracy: 0.8824 - val_loss: 0.8714 - val_accuracy: 0.7358\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2770 - accuracy: 0.9085 - val_loss: 0.9134 - val_accuracy: 0.7366\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2069 - accuracy: 0.9324 - val_loss: 0.9822 - val_accuracy: 0.7344\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1536 - accuracy: 0.9518 - val_loss: 1.1064 - val_accuracy: 0.7302\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1121 - accuracy: 0.9657 - val_loss: 1.1604 - val_accuracy: 0.7370\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0819 - accuracy: 0.9754 - val_loss: 1.3550 - val_accuracy: 0.7252\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0708 - accuracy: 0.9785 - val_loss: 1.3778 - val_accuracy: 0.7166\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0523 - accuracy: 0.9845 - val_loss: 1.4964 - val_accuracy: 0.7212\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 1.5572 - val_accuracy: 0.7236\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 1.5889 - val_accuracy: 0.7242\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 1.6391 - val_accuracy: 0.7232\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0401 - accuracy: 0.9871 - val_loss: 1.7496 - val_accuracy: 0.7266\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 1.7748 - val_accuracy: 0.7254\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 1.8202 - val_accuracy: 0.7276\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0335 - accuracy: 0.9887 - val_loss: 1.8887 - val_accuracy: 0.7192\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 1.9477 - val_accuracy: 0.7280\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-3:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5685 - accuracy: 0.4294 - val_loss: 1.3163 - val_accuracy: 0.5280\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1900 - accuracy: 0.5787 - val_loss: 1.0505 - val_accuracy: 0.6352\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0014 - accuracy: 0.6479 - val_loss: 0.9369 - val_accuracy: 0.6778\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8733 - accuracy: 0.6948 - val_loss: 0.8665 - val_accuracy: 0.7008\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.7710 - accuracy: 0.7318 - val_loss: 0.8448 - val_accuracy: 0.6994\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6843 - accuracy: 0.7644 - val_loss: 0.8158 - val_accuracy: 0.7200\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.5966 - accuracy: 0.7963 - val_loss: 0.7799 - val_accuracy: 0.7404\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5165 - accuracy: 0.8244 - val_loss: 0.8675 - val_accuracy: 0.7208\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.8525 - val_loss: 0.8206 - val_accuracy: 0.7294\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3638 - accuracy: 0.8763 - val_loss: 0.8659 - val_accuracy: 0.7352\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2933 - accuracy: 0.9034 - val_loss: 0.8932 - val_accuracy: 0.7332\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2259 - accuracy: 0.9249 - val_loss: 0.9407 - val_accuracy: 0.7324\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1724 - accuracy: 0.9446 - val_loss: 1.0442 - val_accuracy: 0.7350\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1281 - accuracy: 0.9595 - val_loss: 1.1570 - val_accuracy: 0.7270\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0945 - accuracy: 0.9716 - val_loss: 1.3194 - val_accuracy: 0.7246\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0763 - accuracy: 0.9760 - val_loss: 1.3378 - val_accuracy: 0.7178\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0608 - accuracy: 0.9816 - val_loss: 1.4689 - val_accuracy: 0.7176\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0523 - accuracy: 0.9847 - val_loss: 1.5673 - val_accuracy: 0.7186\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0502 - accuracy: 0.9843 - val_loss: 1.4887 - val_accuracy: 0.7178\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0443 - accuracy: 0.9856 - val_loss: 1.5959 - val_accuracy: 0.7184\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0394 - accuracy: 0.9873 - val_loss: 1.6794 - val_accuracy: 0.7188\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 1.7557 - val_accuracy: 0.7304\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 1.7425 - val_accuracy: 0.7256\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 1.8050 - val_accuracy: 0.7266\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 1.8298 - val_accuracy: 0.7256\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-4:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5576 - accuracy: 0.4355 - val_loss: 1.3103 - val_accuracy: 0.5322\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1822 - accuracy: 0.5829 - val_loss: 1.0454 - val_accuracy: 0.6326\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9987 - accuracy: 0.6479 - val_loss: 0.9319 - val_accuracy: 0.6730\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8714 - accuracy: 0.6942 - val_loss: 0.8646 - val_accuracy: 0.7016\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7694 - accuracy: 0.7302 - val_loss: 0.8536 - val_accuracy: 0.7044\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6867 - accuracy: 0.7633 - val_loss: 0.8041 - val_accuracy: 0.7292\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5998 - accuracy: 0.7939 - val_loss: 0.7577 - val_accuracy: 0.7486\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5198 - accuracy: 0.8220 - val_loss: 0.8524 - val_accuracy: 0.7224\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4428 - accuracy: 0.8487 - val_loss: 0.7916 - val_accuracy: 0.7456\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3678 - accuracy: 0.8755 - val_loss: 0.8492 - val_accuracy: 0.7368\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2980 - accuracy: 0.9001 - val_loss: 0.8731 - val_accuracy: 0.7426\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2261 - accuracy: 0.9260 - val_loss: 0.9631 - val_accuracy: 0.7370\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1723 - accuracy: 0.9438 - val_loss: 1.0475 - val_accuracy: 0.7366\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1259 - accuracy: 0.9611 - val_loss: 1.1210 - val_accuracy: 0.7296\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0945 - accuracy: 0.9709 - val_loss: 1.2071 - val_accuracy: 0.7302\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0739 - accuracy: 0.9780 - val_loss: 1.3505 - val_accuracy: 0.7258\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0629 - accuracy: 0.9805 - val_loss: 1.4082 - val_accuracy: 0.7336\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 1.5199 - val_accuracy: 0.7250\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 1.6208 - val_accuracy: 0.7260\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 1.5845 - val_accuracy: 0.7306\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 1.6766 - val_accuracy: 0.7342\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 1.7828 - val_accuracy: 0.7226\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 1.8149 - val_accuracy: 0.7206\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0370 - accuracy: 0.9875 - val_loss: 1.8510 - val_accuracy: 0.7352\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0323 - accuracy: 0.9898 - val_loss: 1.8495 - val_accuracy: 0.7258\n",
            "\n",
            "\u001b[1m\u001b[92m  Run-5:\u001b[0m\n",
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5691 - accuracy: 0.4288 - val_loss: 1.3345 - val_accuracy: 0.5214\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1896 - accuracy: 0.5824 - val_loss: 1.0629 - val_accuracy: 0.6342\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0028 - accuracy: 0.6486 - val_loss: 0.9470 - val_accuracy: 0.6722\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8752 - accuracy: 0.6949 - val_loss: 0.8866 - val_accuracy: 0.6928\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7752 - accuracy: 0.7290 - val_loss: 0.8547 - val_accuracy: 0.7004\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6874 - accuracy: 0.7651 - val_loss: 0.8364 - val_accuracy: 0.7146\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5988 - accuracy: 0.7936 - val_loss: 0.7745 - val_accuracy: 0.7408\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5164 - accuracy: 0.8239 - val_loss: 0.8548 - val_accuracy: 0.7190\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.8519 - val_loss: 0.8145 - val_accuracy: 0.7322\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3645 - accuracy: 0.8778 - val_loss: 0.8439 - val_accuracy: 0.7332\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2921 - accuracy: 0.9033 - val_loss: 0.8829 - val_accuracy: 0.7438\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.2253 - accuracy: 0.9275 - val_loss: 0.9684 - val_accuracy: 0.7332\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1685 - accuracy: 0.9474 - val_loss: 1.0719 - val_accuracy: 0.7314\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1225 - accuracy: 0.9615 - val_loss: 1.1298 - val_accuracy: 0.7326\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0939 - accuracy: 0.9714 - val_loss: 1.2527 - val_accuracy: 0.7294\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0734 - accuracy: 0.9785 - val_loss: 1.3278 - val_accuracy: 0.7334\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0610 - accuracy: 0.9815 - val_loss: 1.3883 - val_accuracy: 0.7350\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0524 - accuracy: 0.9844 - val_loss: 1.5063 - val_accuracy: 0.7336\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0465 - accuracy: 0.9861 - val_loss: 1.6223 - val_accuracy: 0.7250\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 1.7224 - val_accuracy: 0.7020\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 1.7423 - val_accuracy: 0.7172\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 1.6445 - val_accuracy: 0.7302\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 1.7640 - val_accuracy: 0.7242\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 1.8298 - val_accuracy: 0.7294\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 1.8048 - val_accuracy: 0.7368\n",
            "\u001b[1m\n",
            "\n",
            "search space boundaries:\n",
            "\u001b[0m      dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate\n",
            "min          0          117          0    215          0       0.000378\n",
            "max          0          117          0    329          0       0.000419 \n",
            "\n",
            "\u001b[1mhyperparameters combinations (lHC):\n",
            "\u001b[0m  dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate\n",
            "         0          117          0    295          0       0.000390\n",
            "         0          117          0    318          0       0.000398\n",
            "         0          117          0    226          0       0.000415\n",
            "         0          117          0    249          0       0.000406\n",
            "         0          117          0    272          0       0.000382 \n",
            "\n",
            "\u001b[1mmodels results:\n",
            "\u001b[0m\u001b[0m  dropout_1  num_filters  dropout_2  units  dropout_3  learning_rate      loss  accuracy  val_loss  val_accuracy\n",
            "         0          117          0    295          0       0.000390  0.027875  0.991444  1.809078        0.7332\n",
            "         0          117          0    318          0       0.000398  0.025681  0.991822  1.947742        0.7280\n",
            "         0          117          0    226          0       0.000415  0.030924  0.990400  1.829766        0.7256\n",
            "         0          117          0    249          0       0.000406  0.032270  0.989822  1.849492        0.7258\n",
            "         0          117          0    272          0       0.000382  0.032987  0.989622  1.804759        0.7368\n",
            "\u001b[1m\n",
            "optimization has ended\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCmnrcQ8DYQG"
      },
      "source": [
        "### AI Tuner performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ory03lRQDYQG",
        "outputId": "7050a201-bad6-4f64-a66e-a0f0373b5b67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ai_best_model = tuner.best_model\n",
        "ai_loss, ai_accuracy = ai_best_model.evaluate(x_test, y_test)\n",
        "ai_elapsed_time = end_t - start_t\n",
        "print(f\"Elapsed time (s): {ai_elapsed_time:0.2f} (s)\")\n",
        "print(f'AI Tuner Best model loss: {ai_loss:0.3f}, accuracy: {ai_accuracy:0.3f}%')\n",
        "results.append([ai_elapsed_time, ai_loss, ai_accuracy])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9308 - accuracy: 0.1020\n",
            "Elapsed time (s): 2149.78 (s)\n",
            "AI Tuner Best model loss: 1.931, accuracy: 0.102%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smas6kuIDYQG",
        "outputId": "f6aa9cfd-d32f-4509-ee1a-351432f6f3d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for result in results[0:5]:\n",
        "  print(result)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[122.52753019332886, 0.7809739112854004, 0.7348999977111816]\n",
            "[4663.7847492694855, 0.7547946572303772, 0.7552000284194946]\n",
            "[2718.407343149185, 0.7292322516441345, 0.7501999735832214]\n",
            "[2533.7225046157837, 0.742324709892273, 0.7457000017166138]\n",
            "[2149.7841844558716, 1.930823802947998, 0.10199999809265137]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd0IMnFdfq8v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}